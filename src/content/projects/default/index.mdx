---
title: "Default"
year: "2017"
order: 0
cover: "./cover.jpg"
coverAlt: "Silhouette of a person in the middle of the installation"
tags: ["Interactive installation", "Immersive experience"]
skills:
  [
    "prototyping",
    "data processing",
    "interaction design",
    "Arduino",
    "TouchDesigner",
  ]
color: "#515DAF"
exhibit: "Museo de Arte Contemporáneo (MAC), Santiago"
team:
  [
    "Manuela Garretón",
    "Tomás Ossandón",
    "Karina Hyland",
    "Roy Maconald",
    "Pablo Garretón",
    "Benjamín Benavides",
    "Esteban Sandoval",
  ]
images:
  - "./01.jpg"
  - "./02.jpg"
  - "./03.jpg"
  - "./04.jpg"
alts:
  - "A top view of the installation and the team while being set up."
  - "A person in front of one of the prototypes done to understand the data and the interaction."
  - "A person standing in the middle of the room of the installation."
  - "A person's outline standing in the middle of the room of the installation."

link:
  url: http://xdefault.cl/
  label: Project Website
---

Led by the research of designer Manuela Garretón and the neuroscientist Tomás Ossandón, Default is an interactive and immersive installation that visualizes brain activity in a resting state. It was believed that the brain didn't present relevant activity when not under a stimulus, but the evidence of fMRI scans of these states shows the opposite. This activity is explained by the Default Mode Network (DMN), which demonstrates that the brain is never really resting, as this network is fully active when mind-wandering or introspecting. Memory, self-consciousness, and creativity might be highly interconnected to the activation of this network for the same reason.

Projecting a three-dimensional representation of data from a fMRI scan to three adjacent walls, we created an immersive experience where the user could become part of the brain and navigate this activity by walking around the room. If another person entered the space, the visualization morphed into a single focused graphic, representing the detention of the mind wandering caused by an external stimulus.

Benjamin and I were in charge of coding and designing part of the interaction of the room. We used a Kinect with TouchDesigner to select a user as the controller whenever they stood at the center of the space. Once selected, they could navigate the room as we detected their position and pass it to the visual and audio software. With a sensor in an Arduino at the room's entrance, we could send the signal of the external stimulus and turn on a blue light. We also were part of every prototype that led to the final design, taking part in the processing of the data and the initial design of the visual representation.

<div style="padding:56.25% 0 0 0;position:relative;">
  <iframe
    src="https://player.vimeo.com/video/248526680?h=fdab7e3585&byline=0&portrait=0"
    style="position:absolute;top:0;left:0;width:100%;height:100%;"
    frameborder="0"
    allow="autoplay; fullscreen; picture-in-picture"
    allowfullscreen
  ></iframe>
</div>
<script src="https://player.vimeo.com/api/player.js"></script>
